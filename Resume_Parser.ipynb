{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1d7w0pjW2Rs0Bsxu0YVFjgsGHF0WSdwcP",
      "authorship_tag": "ABX9TyP+Bxz9A3xfx7vPtepmH8kl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushparani7/NLP_project/blob/main/Resume_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up the Environment**"
      ],
      "metadata": {
        "id": "EOXmCWcdEB5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n97MZGJQ8yX3",
        "outputId": "fa26e818-9bbc-4c15-a348-3fbcc830598e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (20250506)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "python3: can't open file '/content/m': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install spacy\n",
        "!python m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Text frpm PDF using Pdfminer**"
      ],
      "metadata": {
        "id": "ClGxukmJD2Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "import os\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "sample_text= extract_text_from_pdf(\"data_analysis_resume.pdf\")\n",
        "print(sample_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE-lCbO19EXw",
        "outputId": "26755413-7845-476f-8184-e89216433593"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume\n",
            "\n",
            "Name\n",
            "\n",
            "Priya Sharma\n",
            "\n",
            "Email\n",
            "\n",
            "priya.sharma@example.com\n",
            "\n",
            "Phone\n",
            "\n",
            "+91 9876543210\n",
            "\n",
            "Skills\n",
            "\n",
            "Python, SQL, Data Visualization, Pandas, NumPy, Machine Learning, Excel, Tableau\n",
            "\n",
            "Education\n",
            "\n",
            "Bachelor of Technology in Artificial Intelligence and Data Science, Anna University, 2021 - 2025\n",
            "\n",
            "Experience\n",
            "\n",
            "Data Analyst Intern, ABC Analytics, June 2024 - Aug 2024\n",
            "\n",
            "- Performed data cleaning, transformation, and visualization using Python and Tableau.\n",
            "\n",
            "- Assisted in building predictive models for sales forecasting.\n",
            "\n",
            "- Collaborated with the team to automate reporting workflows.\n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning & Preprocessing Text**"
      ],
      "metadata": {
        "id": "XgCpfdYWDlGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "  text=re.sub(r'\\n+','\\n',text)\n",
        "  text=re.sub(r'\\+',' ',text)\n",
        "  return text.strip()\n",
        "cleaned=clean_text(sample_text)\n",
        "print(cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biox0Tnl_FJ9",
        "outputId": "13bd20ac-bd9e-428b-954b-4686650374bb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume\n",
            "Name\n",
            "Priya Sharma\n",
            "Email\n",
            "priya.sharma@example.com\n",
            "Phone\n",
            " 91 9876543210\n",
            "Skills\n",
            "Python, SQL, Data Visualization, Pandas, NumPy, Machine Learning, Excel, Tableau\n",
            "Education\n",
            "Bachelor of Technology in Artificial Intelligence and Data Science, Anna University, 2021 - 2025\n",
            "Experience\n",
            "Data Analyst Intern, ABC Analytics, June 2024 - Aug 2024\n",
            "- Performed data cleaning, transformation, and visualization using Python and Tableau.\n",
            "- Assisted in building predictive models for sales forecasting.\n",
            "- Collaborated with the team to automate reporting workflows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Name,E-mail,Phone**"
      ],
      "metadata": {
        "id": "QItxt2RyEQkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_email(text):\n",
        "  match=re.search(r'\\S+@\\S+',text)\n",
        "  return match.group(0) if match else None\n",
        "\n",
        "def extract_phone(text):\n",
        "  match=re.search(r'\\+?\\d[\\d\\s\\_()]{8,15}',text)\n",
        "  return match.group(0) if match else None\n",
        "\n",
        "email=extract_email(cleaned)\n",
        "phone=extract_phone(cleaned)\n",
        "print(\"Email:\",email, \" Phone:\",phone,\"Name:\",name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLQIR6b0Cwcq",
        "outputId": "0845b34d-3432-4096-ee2a-688f3b3f2f52"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: priya.sharma@example.com  Phone: 91 9876543210\n",
            " Name: Priya Sharma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_name(text):\n",
        "  doc=nlp(text)\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_=='PERSON':\n",
        "      return ent.text\n",
        "  return None\n",
        "name = extract_name(cleaned)\n",
        "print(\"Extracted Name:\", name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCPeZCMeHnzo",
        "outputId": "4f6885ea-3c75-402b-a07e-e6b3e35d244c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Name: Priya Sharma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Skill Matching from Resume**"
      ],
      "metadata": {
        "id": "RBujiRJrLjoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SKILL_SET=['python','Excel','Machine learning','SQL','power bi','data Analysis']\n",
        "\n",
        "def extract_skills(text,skills=SKILL_SET):\n",
        "  found=[skill for skill in skills if skill.lower() in text.lower()]\n",
        "  return list(set(found))"
      ],
      "metadata": {
        "id": "AGje2lBkLqkv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Education & Degree**"
      ],
      "metadata": {
        "id": "L6_FqzPUNJtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EDU_KEYWORDS=['Bachelor','B.tech','M.tech','B.E','M.E','PhD']\n",
        "\n",
        "def extract_education(text):\n",
        "  lines=text.split('\\n')\n",
        "  education=[]\n",
        "  for line in lines:\n",
        "    for word in EDU_KEYWORDS:\n",
        "      if word.lower() in line.lower():\n",
        "        education.append(line.strip())\n",
        "  return education"
      ],
      "metadata": {
        "id": "U15wQooVNTqN"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Work Experiences Snippet**"
      ],
      "metadata": {
        "id": "85vtRF7AObK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_experience(text):\n",
        "  experience_keywords=['experience','work','internship','employment']\n",
        "  exp_lines=[]\n",
        "\n",
        "  lines=text.split('\\n')\n",
        "  for line in lines:\n",
        "    for keyword in experience_keywords:\n",
        "      if keyword.lower() in line.lower():\n",
        "        exp_lines.append(line.strip())\n",
        "  return exp_lines"
      ],
      "metadata": {
        "id": "ib8leAEYOhhs"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINAL OUTPUT DICTIONARY**"
      ],
      "metadata": {
        "id": "SQGcKhOMQOCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_resume={\n",
        "    'name':extract_name(cleaned),\n",
        "    'email':extract_email(cleaned),\n",
        "    'phone':extract_phone(cleaned),\n",
        "    'skills':extract_skills(cleaned),\n",
        "    'education':extract_education(cleaned),\n",
        "    'experience':extract_experience(cleaned)\n",
        "}\n",
        "print(parsed_resume)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFdRpH68QS7M",
        "outputId": "e5157b0c-4641-43cf-f66e-c5a929d2460b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'Priya Sharma', 'email': 'priya.sharma@example.com', 'phone': '91 9876543210\\n', 'skills': ['SQL', 'Machine learning', 'python', 'Excel'], 'education': ['Bachelor of Technology in Artificial Intelligence and Data Science, Anna University, 2021 - 2025'], 'experience': ['Experience', '- Collaborated with the team to automate reporting workflows.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Automating Resume Folder Parcing**"
      ],
      "metadata": {
        "id": "Dwm0fXBXT7hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_folder(folder_path):\n",
        "  results=[]\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.pdf'):\n",
        "      path=os.path.join(folder_path,filename)\n",
        "      text=clean_text(extract_text_from_pdf(pdf_path))\n",
        "      parsed={\n",
        "          'filename':filename,\n",
        "          'name':extract_name(text),\n",
        "          'email':extract_email(text),\n",
        "          'phone':extract_phone(text),\n",
        "          'skills':extract_skills(text),\n",
        "          'education':extract_education(text),\n",
        "          'experience':extract_experience(text)\n",
        "\n",
        "      }\n",
        "      results.append(parsed)\n",
        "  return pd.DataFrame(results)\n",
        "df=process_folder('resumes')\n",
        "df.to_csv('parsed_resumes.csv',index=False)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "2Twekg7qbYDQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}